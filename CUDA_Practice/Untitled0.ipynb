{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8OvTKqO_tD-",
        "outputId": "30c405dd-9900-4d8b-82c3-540c0d4ae4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x4i4l4_0L2",
        "outputId": "49314087-2327-4e72-c284-b2291104558e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGktjoae_4N2",
        "outputId": "4430227b-8d18-4333-d647-90edac0a2fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-dverefym\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-dverefym\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=5e10033b38f805781b82d1f93e354775da7d1cdc3d6c6f42a9071e2a59dd8681\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6pl79w8t/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7b0wZbx_777",
        "outputId": "6bfa91ca-bfff-423d-a23a-5007f0891849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg1.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define TILE_WIDTH 2\n",
        "#define WIDTH 4\n",
        "#define MASK_WIDTH 3\n",
        "\n",
        "__global__ void convolution(int* input, int* mask, int* output) {\n",
        "    int row = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    int sum = 0;\n",
        "    for (int i = 0; i < MASK_WIDTH; i++) {\n",
        "        for (int j = 0; j < MASK_WIDTH; j++) {\n",
        "            int inputRow = row + i - MASK_WIDTH / 2;\n",
        "            int inputCol = col + j - MASK_WIDTH / 2;\n",
        "            if (inputRow >= 0 && inputRow < WIDTH && inputCol >= 0 && inputCol < WIDTH) {\n",
        "                sum += input[inputRow * WIDTH + inputCol] * mask[i * MASK_WIDTH + j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    output[row * WIDTH + col] = sum;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *input, *mask, *output, *d_input, *d_mask, *d_output;\n",
        "    input = (int*)malloc(sizeof(int) * WIDTH * WIDTH);\n",
        "    output = (int*)malloc(sizeof(int) * WIDTH * WIDTH);\n",
        "    mask = (int*)malloc(sizeof(int) * MASK_WIDTH * MASK_WIDTH);\n",
        "    printf(\"Enter the (4x4) input matrix:\\n\");\n",
        "    for (int i = 0; i < WIDTH; i++) {\n",
        "        for (int j = 0; j < WIDTH; j++) {\n",
        "            scanf(\"%d\", &input[i * WIDTH + j]);\n",
        "        }\n",
        "    }\n",
        "    printf(\"Enter the (3x3) mask matrix:\\n\");\n",
        "    for (int i = 0; i < MASK_WIDTH; i++) {\n",
        "        for (int j = 0; j < MASK_WIDTH; j++) {\n",
        "            scanf(\"%d\", &mask[i * MASK_WIDTH + j]);\n",
        "        }\n",
        "    }\n",
        "    cudaMalloc((void**)&d_input, WIDTH * WIDTH * sizeof(int));\n",
        "    cudaMalloc((void**)&d_mask, MASK_WIDTH * MASK_WIDTH * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, WIDTH * WIDTH * sizeof(int));\n",
        "    cudaMemcpy(d_input, input, WIDTH * WIDTH * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mask, mask, MASK_WIDTH * MASK_WIDTH * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    dim3 grid_conf(WIDTH / TILE_WIDTH, WIDTH / TILE_WIDTH);\n",
        "    dim3 block_conf(TILE_WIDTH, TILE_WIDTH);\n",
        "    convolution<<<grid_conf, block_conf>>>(d_input, d_mask, d_output);\n",
        "    cudaMemcpy(output, d_output, WIDTH * WIDTH * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"After performing convolution:\\n\");\n",
        "    for (int i = 0; i < WIDTH; i++) {\n",
        "        for (int j = 0; j < WIDTH; j++) {\n",
        "            printf(\"%d \", output[i * WIDTH + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_mask);\n",
        "    cudaFree(d_output);\n",
        "    free(input);\n",
        "    free(output);\n",
        "    free(mask);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qSoMmohO_93t",
        "outputId": "d0956ad9-f9fc-4fb6-e753-2657304acdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg1.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg1.cu -o /content/src/prg1"
      ],
      "metadata": {
        "id": "Z2iHomdtAHtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjpNFKHAx1W",
        "outputId": "be1e32f2-6ab1-41aa-876d-0ef473bed037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the (4x4) input matrix:\n",
            "1 2 3 4\n",
            "5 6 7 8\n",
            "9 10 11 12\n",
            "13 14 15 16\n",
            "Enter the (3x3) mask matrix:\n",
            "1 2 3\n",
            "4 5 6\n",
            "7 8 9\n",
            "After performing convolution:\n",
            "111 178 217 145 \n",
            "231 348 393 252 \n",
            "363 528 573 360 \n",
            "197 274 295 175 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg2.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define BLOCK_WIDTH 2\n",
        "#define TILE_WIDTH 2\n",
        "#define WIDTH 4\n",
        "\n",
        "__global__ void matMul(int* a,int* b,int* c){\n",
        "    __shared__ int MD[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__  int ND[TILE_WIDTH][TILE_WIDTH];\n",
        "    int m;\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int row = by*TILE_WIDTH + ty;\n",
        "    int col = bx*TILE_WIDTH + tx;\n",
        "    int pval = 0;\n",
        "    for(m = 0;m < WIDTH/TILE_WIDTH;m++){\n",
        "        MD[tx][ty] = a[row*WIDTH + m * TILE_WIDTH+tx];\n",
        "        ND[tx][ty] = b[(m*TILE_WIDTH + ty)* WIDTH+col];\n",
        "        __syncthreads();\n",
        "        for(int k = 0;k < TILE_WIDTH;k++){\n",
        "            pval += MD[ty][k]*ND[k][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "    c[row*WIDTH + col] = pval;\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int* matA,*matB,*matC,*d_a,*d_b,*d_c;\n",
        "    matA = (int*)malloc(WIDTH*WIDTH*sizeof(int));\n",
        "    printf(\"Enter the elements of 4x4 matA:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "      scanf(\"%d\",&matA[i]);\n",
        "    matB = (int*)malloc(WIDTH*WIDTH*sizeof(int));\n",
        "    printf(\"Enter the elements of 4x4 matB:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "      scanf(\"%d\",&matB[i]);\n",
        "    matC = (int*)malloc(WIDTH*WIDTH*sizeof(int));\n",
        "    cudaMalloc((void**)&d_a,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&d_b,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&d_c,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMemcpy(d_a,matA,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,matB,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    dim3 grid_conf(WIDTH/TILE_WIDTH,WIDTH/TILE_WIDTH);\n",
        "    dim3 block_conf(TILE_WIDTH,TILE_WIDTH);\n",
        "    matMul<<<grid_conf,block_conf>>>(d_a,d_b,d_c);\n",
        "    cudaMemcpy(matC,d_c,sizeof(int)*WIDTH*WIDTH,cudaMemcpyDeviceToHost);\n",
        "    printf(\"Result:\\n\");\n",
        "    for(int i = 0;i < WIDTH;i++){\n",
        "      for(int j = 0;j < WIDTH;j++){\n",
        "        printf(\"%d \",matC[i*WIDTH + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(matA);\n",
        "    free(matB);\n",
        "    free(matC);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XiGvjLjlpAxJ",
        "outputId": "81a31783-9986-499c-88bb-95959f6f219c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg2.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg2.cu -o /content/src/prg2"
      ],
      "metadata": {
        "id": "kPWMoxKvpFgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abogAY9MpOD1",
        "outputId": "68343526-cac5-49f5-ffa7-8b297b54757b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the elements of 4x4 matA:\n",
            "1 2 3 4\n",
            "5 6 7 8\n",
            "9 10 11 12\n",
            "13 14 15 16\n",
            "Enter the elements of 4x4 matB:\n",
            "1 2 3 4 \n",
            "5 6 7 8\n",
            "9 10 11 12 \n",
            "13 14 15 16\n",
            "Result:\n",
            "108 172 140 204 \n",
            "130 210 170 250 \n",
            "284 476 380 572 \n",
            "306 514 410 618 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg3.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void odd(int *a, int n) {\n",
        "    int tid = blockDim.x*blockIdx.x + threadIdx.x ;\n",
        "    if (tid%2 != 0 && tid + 1 < n) {\n",
        "        if (a[tid] > a[tid + 1]) {\n",
        "            int temp = a[tid];\n",
        "            a[tid] = a[tid + 1];\n",
        "            a[tid + 1] = temp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void even(int *a, int n) {\n",
        "    int tid = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "    if (tid % 2 == 0 && tid + 1 < n) {\n",
        "        if (a[tid] > a[tid + 1]) {\n",
        "            int temp = a[tid];\n",
        "            a[tid] = a[tid + 1];\n",
        "            a[tid + 1] = temp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *a, n, *d_a;\n",
        "    printf(\"Enter the size of the array:\\n\");\n",
        "    scanf(\"%d\", &n);\n",
        "    printf(\"Enter the array elements:\\n\");\n",
        "    a = (int*)malloc(sizeof(int) * n);\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        scanf(\"%d\", &a[i]);\n",
        "    }\n",
        "    cudaMalloc((void**)&d_a, sizeof(int) * n);\n",
        "    cudaMemcpy(d_a, a, sizeof(int) * n, cudaMemcpyHostToDevice);\n",
        "    for (int i = 0; i < n / 2; i++) {\n",
        "        odd<<<1, n>>>(d_a, n);\n",
        "        even<<<1, n>>>(d_a, n);\n",
        "    }\n",
        "    cudaMemcpy(a, d_a, sizeof(int) * n, cudaMemcpyDeviceToHost);\n",
        "    printf(\"Result:\\n\");\n",
        "    for (int i = 0; i < n; i++)\n",
        "        printf(\"%d \", a[i]);\n",
        "    cudaFree(d_a);\n",
        "    free(a);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NzbVKMbt7eEi",
        "outputId": "704eb2c5-49eb-44c6-f841-bdbba5d3256f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg3.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg3.cu -o /content/src/prg3"
      ],
      "metadata": {
        "id": "hhMvX-Jt-4fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLme-RzH_PPP",
        "outputId": "fc659539-db07-43c0-9e50-14f79ff3a7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the array:\n",
            "4\n",
            "Enter the array elements:\n",
            "9 1 0 11\n",
            "Result:\n",
            "0 1 9 11 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg4.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#define MASK_SIZE 3\n",
        "\n",
        "__constant__ int mask[MASK_SIZE];\n",
        "\n",
        "__global__ void convolution(int* input, int* output, int width) {\n",
        "    int tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (tid < width) {\n",
        "        int res = 0;\n",
        "        for (int i = 0; i < MASK_SIZE; i++) {\n",
        "            int idx = tid - MASK_SIZE / 2 + i;\n",
        "            if (idx >= 0 && idx < width) {\n",
        "                res += input[idx] * mask[i];\n",
        "            }\n",
        "        }\n",
        "        output[tid] = res;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int width, *input, *output, *d_input, *d_output;\n",
        "    printf(\"Enter the width:\\n\");\n",
        "    scanf(\"%d\", &width);\n",
        "    input = (int*)malloc(sizeof(int) * width);\n",
        "    output = (int*)malloc(sizeof(int) * width);\n",
        "\n",
        "    printf(\"Enter the array elements:\\n\");\n",
        "    for (int i = 0; i < width; i++)\n",
        "        scanf(\"%d\", &input[i]);\n",
        "\n",
        "    printf(\"Enter the mask elements:\\n\");\n",
        "    int maskElements[MASK_SIZE];\n",
        "    for (int i = 0; i < MASK_SIZE; i++)\n",
        "        scanf(\"%d\", &maskElements[i]);\n",
        "\n",
        "    // Copy the mask to constant memory\n",
        "    cudaMemcpyToSymbol(mask, maskElements, MASK_SIZE * sizeof(int));\n",
        "\n",
        "    cudaMalloc((void**)&d_input, sizeof(int) * width);\n",
        "    cudaMalloc((void**)&d_output, sizeof(int) * width);\n",
        "    cudaMemcpy(d_input, input, sizeof(int) * width, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (width + blockSize - 1) / blockSize;\n",
        "    convolution<<<gridSize, blockSize>>>(d_input, d_output, width);\n",
        "    cudaMemcpy(output, d_output, sizeof(int) * width, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Result:\\n\");\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        printf(\"%d \", output[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    free(input);\n",
        "    free(output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6KOrOtsjCLY0",
        "outputId": "c2210185-b5b1-4a59-f0e5-aabc7e585d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg4.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg4.cu -o /content/src/prg4"
      ],
      "metadata": {
        "id": "kmetf_w2M_K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpmIQMyiNWIR",
        "outputId": "478a4e09-d44a-417f-bfd9-55fec94e9e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the width:\n",
            "5\n",
            "Enter the array elements:\n",
            "1 2 3 4 5\n",
            "Enter the mask elements:\n",
            "1 2 3 4\n",
            "Result:\n",
            "8 14 20 26 14 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg1.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define BLOCK_WIDTH 2\n",
        "#define TILE_WIDTH 2\n",
        "#define WIDTH 4\n",
        "\n",
        "__global__ void matMul(int* a,int* b,int* c){\n",
        "    __shared__ int MD[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ND[TILE_WIDTH][TILE_WIDTH];\n",
        "    int m;\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int row = by*TILE_WIDTH + ty;\n",
        "    int col = bx*TILE_WIDTH + tx;\n",
        "    int pval = 0;\n",
        "    for(m=0;m < TILE_WIDTH/WIDTH;m++){\n",
        "        MD[tx][ty] = a[row*WIDTH + m*TILE_WIDTH + tx];\n",
        "        ND[tx][ty] = b[m*TILE_WIDTH + ty*WIDTH + col];\n",
        "        __syncthreads();\n",
        "        for(int k = 0;k < TILE_WIDTH;k++){\n",
        "            pval += MD[ty][k]*ND[k][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    c[row*WIDTH + col] = pval;\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int* a,*b,*c,*da,*db,*dc;\n",
        "    a = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    b = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    c = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    printf(\"Enter a 4x4 matrix A:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "        scanf(\"%d\",&a[i]);\n",
        "    printf(\"Enter a 4x4 matrix B:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "        scanf(\"%d\",&b[i]);\n",
        "    cudaMalloc((void**)&da,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&db,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&dc,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMemcpy(da,a,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(db,b,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    dim3 grid_conf(WIDTH/TILE_WIDTH,WIDTH/TILE_WIDTH);\n",
        "    dim3 block_conf(TILE_WIDTH,TILE_WIDTH);\n",
        "    matMul<<<grid_conf,block_conf>>>(da,db,dc);\n",
        "    cudaMemcpy(c,dc,sizeof(int)*WIDTH*WIDTH,cudaMemcpyDeviceToHost);\n",
        "    printf(\"Result:\\n\");\n",
        "    for(int i = 0;i < WIDTH;i++){\n",
        "        for(int j = 0;j < WIDTH;j++){\n",
        "            printf(\"%d \", c[i*WIDTH + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaFree(da);\n",
        "    cudaFree(db);\n",
        "    cudaFree(dc);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wdKeJC7lA6we",
        "outputId": "dc5638bc-3413-437c-8bb7-4e0f29683938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg1.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg1.cu -o /content/src/prg1"
      ],
      "metadata": {
        "id": "m9kkUsGaBzsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roPVK3YPB4uC",
        "outputId": "68107596-7ca7-4adb-8298-f75a21b233b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a 4x4 matrix A:\n",
            "1 2 3 4\n",
            "5 6 7 8 \n",
            "9 10 11 12\n",
            "13 14 15 16\n",
            "Enter a 4x4 matrix B:\n",
            "1 2 3 4\n",
            "5 6 7 8 \n",
            "9 10 11 12\n",
            "13 14 15 16\n",
            "Result:\n",
            "0 0 0 0 \n",
            "0 0 0 0 \n",
            "0 0 0 0 \n",
            "0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg1.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define WIDTH 4\n",
        "#define TILE_WIDTH 4\n",
        "__global__ void matMul(int* a,int* b,int* c){\n",
        "    __shared__ int MD[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ND[TILE_WIDTH][TILE_WIDTH];\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int res = 0;\n",
        "    int row = by*TILE_WIDTH + ty;\n",
        "    int col = bx*TILE_WIDTH + tx;\n",
        "    int m;\n",
        "    for(m = 0; m < WIDTH/TILE_WIDTH;m++){\n",
        "        MD[tx][ty] = a[row*WIDTH + m*TILE_WIDTH+ tx];\n",
        "        ND[tx][ty] = a[m*TILE_WIDTH + ty*WIDTH+ col];\n",
        "        __syncthreads();\n",
        "        for(int k = 0;k < TILE_WIDTH;k++){\n",
        "            res += MD[ty][k]*ND[k][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    c[row*WIDTH + col] = res;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int* a,*b,*c,*da,*db,*dc;\n",
        "    a = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    b = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    c = (int*)malloc(sizeof(int)*WIDTH*WIDTH);\n",
        "    printf(\"Enter the matrix A:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "      scanf(\"%d\",&a[i]);\n",
        "    printf(\"Enter the matrix B:\\n\");\n",
        "    for(int i = 0;i < WIDTH*WIDTH;i++)\n",
        "      scanf(\"%d\",&b[i]);\n",
        "    cudaMalloc((void**)&da,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&db,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMalloc((void**)&dc,sizeof(int)*WIDTH*WIDTH);\n",
        "    cudaMemcpy(da,a,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(db,b,sizeof(int)*WIDTH*WIDTH,cudaMemcpyHostToDevice);\n",
        "    dim3 grid_conf(WIDTH/TILE_WIDTH,WIDTH/TILE_WIDTH);\n",
        "    dim3 block_conf(TILE_WIDTH,TILE_WIDTH);\n",
        "    matMul<<<grid_conf,block_conf>>>(da,db,dc);\n",
        "    cudaMemcpy(c,dc,sizeof(int)*WIDTH*WIDTH,cudaMemcpyDeviceToHost);\n",
        "    printf(\"Result:\\n\");\n",
        "    for(int i = 0;i < WIDTH;i++){\n",
        "        for(int j = 0; j < WIDTH;j++){\n",
        "            printf(\"%d \", c[i*WIDTH + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaFree(da);\n",
        "    cudaFree(db);\n",
        "    cudaFree(dc);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "_1cGBFx2DSaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f85ff67a-a16d-4919-a04d-3012467a3daf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg1.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg1.cu -o /content/src/prg1"
      ],
      "metadata": {
        "id": "GH-mAMZ5HQbu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh0_hqT_HTVF",
        "outputId": "5d244477-d1f4-4068-b779-ef450adf5409"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the matrix A:\n",
            "1 2 3 4\n",
            "5 6 7 8 \n",
            "9 10 11 12 \n",
            "13 14 15 16\n",
            "Enter the matrix B:\n",
            "1 2 3 4\n",
            "5 6 7 8 \n",
            "9 10 11 12\n",
            "13 14 15 16\n",
            "Result:\n",
            "90 202 314 426 \n",
            "100 228 356 484 \n",
            "110 254 398 542 \n",
            "120 280 440 600 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg2.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "\n",
        "__global__ void odd(int* a,int n){\n",
        "    int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if(tid % 2 != 0 && tid + 1 < n){\n",
        "        if(a[tid] > a[tid + 1]){\n",
        "            int temp = a[tid];\n",
        "            a[tid] = a[tid + 1];\n",
        "            a[tid + 1] = temp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void even(int* a,int n){\n",
        "    int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if(tid % 2 == 0 && tid + 1 < n){\n",
        "        if(a[tid] > a[tid + 1]){\n",
        "            int temp = a[tid];\n",
        "            a[tid] = a[tid + 1];\n",
        "            a[tid + 1] = temp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int* a,n,*da;\n",
        "    printf(\"Enter n:\\n\");\n",
        "    scanf(\"%d\", &n);\n",
        "    printf(\"Enter the array elements:\\n\");\n",
        "    a = (int*)malloc(sizeof(int)*n);\n",
        "    for(int i = 0;i < n;i++){\n",
        "        scanf(\"%d\",&a[i]);\n",
        "    }\n",
        "    cudaMalloc((void**)&da,sizeof(int)*n);\n",
        "    cudaMemcpy(da,a,sizeof(int)*n,cudaMemcpyHostToDevice);\n",
        "    for(int i = 0;i < n;i++){\n",
        "        odd<<<1,n>>>(da,n);\n",
        "        even<<<1,n>>>(da,n);\n",
        "    }\n",
        "    cudaMemcpy(a,da,sizeof(int)*n,cudaMemcpyDeviceToHost);\n",
        "    printf(\"Result:\\n\");\n",
        "    for(int i = 0;i < n;i++){\n",
        "        printf(\"%d \",a[i]);\n",
        "    }\n",
        "    cudaFree(da);\n",
        "    free(a);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iNF8VQR1IUlV",
        "outputId": "2e006164-287d-4b8a-e881-fc60afdba11c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/prg2.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/src/prg2.cu -o /content/src/prg2"
      ],
      "metadata": {
        "id": "9-AyRAZLKzoV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/prg2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oMNWZN6K5S4",
        "outputId": "d7678383-62e7-4133-b222-8a316e6740e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter n:\n",
            "6\n",
            "Enter the array elements:\n",
            "10 1 9 0 7 4\n",
            "Result:\n",
            "0 1 4 7 9 10 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name prg3.cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "#define TILE_SIZE 32\n",
        "\n",
        "__global__ void convolution(int* N,int* M,int* P,int width,int mask_width){\n",
        "    __shared__  int N_tile[TILE_SIZE + 2 * (MASK_WIDTH / 2)];\n",
        "    int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int start = i - (mask_width/2);\n",
        "    int local_index = threadIdx.x  + mask_width/2;\n",
        "    if(start >= 0 && start < width){\n",
        "        N_tile[local_index] = start;\n",
        "    } else{\n",
        "        N_tile[local_index] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    int pval = 0;\n",
        "    for(int j = 0;j < mask_width;j++){\n",
        "        pval += N_tile[local_index + j ]\n",
        "    }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "FHA2BqWkLMLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}